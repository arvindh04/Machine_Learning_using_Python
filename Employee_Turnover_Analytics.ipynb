{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3250157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07416384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "OUTDIR = \"D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\"\n",
    "os.makedirs(OUTDIR, exist_ok=True)\n",
    "ensure_dir(OUTDIR)\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    path = os.path.join(OUTDIR, name)\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=120)\n",
    "    print(f\"Saved: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6bd38e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1. Load data & data quality checks ----------\n",
    "def load_and_qc(path=\"D:/Microsoft AI Engineer Program/Machine Learning using Python/HR_comma_sep.csv\"):\n",
    "    df = pd.read_csv(path)\n",
    "    print(\"Loaded dataset shape:\", df.shape)\n",
    "    print(\"\\n--- Missing values ---\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n--- Data types ---\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n--- Value counts for target 'left' ---\")\n",
    "    print(df['left'].value_counts())\n",
    "    return df\n",
    "\n",
    "# ---------- 2. Exploratory Data Analysis ----------\n",
    "def eda_plots(df):\n",
    "    # correlation heatmap for numeric features\n",
    "    numeric = df.select_dtypes(include=np.number)\n",
    "    corr = numeric.corr()\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    cax = ax.imshow(corr, interpolation='nearest', aspect='auto')\n",
    "    ax.set_xticks(range(len(corr.columns))); ax.set_yticks(range(len(corr.index)))\n",
    "    ax.set_xticklabels(corr.columns, rotation=45, ha='right'); ax.set_yticklabels(corr.index)\n",
    "    fig.colorbar(cax, ax=ax)\n",
    "    ax.set_title(\"Correlation matrix (numeric)\")\n",
    "    save_fig(fig, \"corr_matrix.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Histograms\n",
    "    for col in ['satisfaction_level','last_evaluation','average_montly_hours']:\n",
    "        fig, ax = plt.subplots(figsize=(5,3))\n",
    "        ax.hist(df[col], bins=30)\n",
    "        ax.set_title(col)\n",
    "        save_fig(fig, f\"hist_{col}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Bar: number_project vs left\n",
    "    proj_counts = df.groupby(['number_project','left']).size().unstack(fill_value=0)\n",
    "    fig, ax = plt.subplots(figsize=(8,4))\n",
    "    x = np.arange(len(proj_counts.index))\n",
    "    width = 0.35\n",
    "    ax.bar(x - width/2, proj_counts[0].values, width=width, label='Stayed (0)')\n",
    "    ax.bar(x + width/2, proj_counts[1].values, width=width, label='Left (1)')\n",
    "    ax.set_xticks(x); ax.set_xticklabels(proj_counts.index)\n",
    "    ax.set_xlabel(\"Number of projects\"); ax.set_ylabel(\"Count\"); ax.legend()\n",
    "    save_fig(fig, \"proj_count_left_vs_stay.png\")\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d43ed1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 3. Which factors contribute most to turnover ----------\n",
    "def feature_importance(df, random_state=42):\n",
    "    # One-hot encode categorical columns: 'sales' (department) and 'salary'\n",
    "    df_enc = pd.get_dummies(df, columns=['sales','salary'], drop_first=True)\n",
    "    X = df_enc.drop('left', axis=1)\n",
    "    y = df_enc['left']\n",
    "\n",
    "    # Train/test split (stratified)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.2, stratify=y,\n",
    "                                                        random_state=random_state)\n",
    "\n",
    "    # Apply SMOTE on training for fair feature importance (train balanced)\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Scale numeric features only (after resampling)\n",
    "    scaler = StandardScaler()\n",
    "    X_train_res_s = scaler.fit_transform(X_train_res)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "\n",
    "    # RandomForest for feature importance\n",
    "    rf = RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1)\n",
    "    rf.fit(X_train_res_s, y_train_res)\n",
    "\n",
    "    # Permutation importance (robust)\n",
    "    r = permutation_importance(rf, X_train_res_s, y_train_res, n_repeats=25, random_state=random_state, n_jobs=-1)\n",
    "    features = X.columns\n",
    "    imp_df = pd.DataFrame({\"feature\": features, \"importance_mean\": r.importances_mean, \"importance_std\": r.importances_std})\n",
    "    imp_df = imp_df.sort_values(\"importance_mean\", ascending=False).reset_index(drop=True)\n",
    "    imp_path = os.path.join(OUTDIR, \"feature_importances.csv\")\n",
    "    imp_df.to_csv(imp_path, index=False)\n",
    "    print(f\"Saved feature importances to {imp_path}\")\n",
    "\n",
    "    # Plot top 12\n",
    "    top = imp_df.head(12)[::-1]\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    ax.barh(top['feature'], top['importance_mean'], xerr=top['importance_std'])\n",
    "    ax.set_title(\"Top feature importances (permutation - RandomForest on SMOTE train)\")\n",
    "    save_fig(fig, \"feature_importances.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Also show logistic regression coefficients for sign direction\n",
    "    lr = LogisticRegression(max_iter=2000, random_state=random_state)\n",
    "    lr.fit(X_train_res_s, y_train_res)\n",
    "    coefs = pd.Series(lr.coef_[0], index=features).sort_values(key=abs, ascending=False)\n",
    "    coef_df = pd.DataFrame({\"feature\": coefs.index, \"coef\": coefs.values})\n",
    "    coef_df.to_csv(os.path.join(OUTDIR, \"logistic_coefs.csv\"), index=False)\n",
    "    print(f\"Saved logistic coefficients to {os.path.join(OUTDIR, 'logistic_coefs.csv')}\")\n",
    "\n",
    "    return imp_df, coef_df, (X_train_res_s, y_train_res, X_test_s, y_test, scaler, X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e34fa62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 4. Clustering of employees who left (satisfaction & evaluation) ----------\n",
    "def cluster_left(df, n_clusters=3, random_state=42):\n",
    "    left_df = df[df['left']==1][['satisfaction_level','last_evaluation']].dropna()\n",
    "    if left_df.shape[0] == 0:\n",
    "        print(\"No rows where left==1 to cluster.\")\n",
    "        return None\n",
    "    scaler = StandardScaler()\n",
    "    Xc = scaler.fit_transform(left_df)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "    labels = kmeans.fit_predict(Xc)\n",
    "    centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "\n",
    "    # Save scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(6,5))\n",
    "    for c in range(n_clusters):\n",
    "        sel = left_df[labels==c]\n",
    "        ax.scatter(sel['satisfaction_level'], sel['last_evaluation'], s=18, alpha=0.6, label=f'Cluster {c}')\n",
    "    ax.scatter(centers[:,0], centers[:,1], marker='X', s=120, edgecolor='k', label='Centers')\n",
    "    ax.set_xlabel('satisfaction_level'); ax.set_ylabel('last_evaluation'); ax.legend()\n",
    "    ax.set_title('KMeans clusters (employees who left)')\n",
    "    save_fig(fig, \"kmeans_left_clusters.png\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    center_df = pd.DataFrame(centers, columns=['satisfaction_level','last_evaluation'])\n",
    "    center_df.to_csv(os.path.join(OUTDIR, \"kmeans_centers.csv\"), index_label='cluster')\n",
    "    print(f\"Saved cluster centers to {os.path.join(OUTDIR, 'kmeans_centers.csv')}\")\n",
    "    return labels, center_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "396c342c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 5. Handle class imbalance using SMOTE ----------\n",
    "def apply_smote(X_train, y_train, random_state=42):\n",
    "    sm = SMOTE(random_state=random_state)\n",
    "    X_res, y_res = sm.fit_resample(X_train, y_train)\n",
    "    print(\"After SMOTE, class distribution:\", np.bincount(y_res))\n",
    "    return X_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c637b9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 6. k-fold cross-validation training and evaluation ----------\n",
    "def train_and_evaluate_models(X_train_res_s, y_train_res, X_test_s, y_test, feature_names, random_state=42):\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=2000, random_state=random_state),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, random_state=random_state)\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    summary = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        # Cross-validated predictions on the SMOTE-upsampled train\n",
    "        print(f\"\\n--- CV (train, upsampled) for {name} ---\")\n",
    "        y_cv_pred = cross_val_predict(model, X_train_res_s, y_train_res, cv=cv, n_jobs=-1)\n",
    "        print(classification_report(y_train_res, y_cv_pred, digits=4))\n",
    "        prec_cv = precision_score(y_train_res, y_cv_pred)\n",
    "        rec_cv = recall_score(y_train_res, y_cv_pred)\n",
    "        acc_cv = accuracy_score(y_train_res, y_cv_pred)\n",
    "        # fit on full upsampled train\n",
    "        model.fit(X_train_res_s, y_train_res)\n",
    "        # evaluate on test set\n",
    "        y_test_pred = model.predict(X_test_s)\n",
    "        y_test_prob = model.predict_proba(X_test_s)[:,1] if hasattr(model, \"predict_proba\") else model.decision_function(X_test_s)\n",
    "        roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "        prec_test = precision_score(y_test, y_test_pred)\n",
    "        rec_test = recall_score(y_test, y_test_pred)\n",
    "        acc_test = accuracy_score(y_test, y_test_pred)\n",
    "        print(f\"Test set: accuracy={acc_test:.4f} precision={prec_test:.4f} recall={rec_test:.4f} ROC_AUC={roc_auc:.4f}\")\n",
    "        print(\"Confusion matrix (test):\\n\", confusion_matrix(y_test, y_test_pred))\n",
    "        # store summary\n",
    "        summary.append({\n",
    "            \"model\": name,\n",
    "            \"cv_precision\": prec_cv, \"cv_recall\": rec_cv, \"cv_accuracy\": acc_cv,\n",
    "            \"test_precision\": prec_test, \"test_recall\": rec_test, \"test_accuracy\": acc_test, \"test_roc_auc\": roc_auc,\n",
    "            \"model_obj\": model\n",
    "        })\n",
    "\n",
    "        # Save ROC curve figure\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_test_prob)\n",
    "        fig, ax = plt.subplots(figsize=(6,5))\n",
    "        ax.plot(fpr, tpr, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "        ax.plot([0,1],[0,1],'--', linewidth=0.7)\n",
    "        ax.set_xlabel(\"False Positive Rate\"); ax.set_ylabel(\"True Positive Rate (Recall)\")\n",
    "        ax.set_title(f\"ROC curve - {name}\")\n",
    "        ax.legend()\n",
    "        save_fig(fig, f\"roc_{name}.png\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Create summary dataframe and save\n",
    "    summary_df = pd.DataFrame(summary).drop(columns=['model_obj'])\n",
    "    summary_df.to_csv(os.path.join(OUTDIR, \"model_summary.csv\"), index=False)\n",
    "    print(f\"\\nSaved model summary to {os.path.join(OUTDIR, 'model_summary.csv')}\")\n",
    "    return summary, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78fc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 7. Pick best model and produce risk zones CSV ----------\n",
    "def predict_and_save_risk_zones(best_model, scaler, X_test_original, X_test_s, \n",
    "                                output_csv=os.path.join(OUTDIR, \"hr_test_probs_with_zones.csv\")):\n",
    "    # best_model should be fitted already\n",
    "    if not hasattr(best_model, \"predict_proba\"):\n",
    "        raise ValueError(\"Best model must support predict_proba for probability-based risk zones.\")\n",
    "\n",
    "    probs = best_model.predict_proba(X_test_s)[:, 1]\n",
    "\n",
    "    # Create risk zones\n",
    "    zones = pd.cut(\n",
    "        probs,\n",
    "        bins=[-0.001, 0.20, 0.60, 0.90, 1.001],\n",
    "        labels=[\"Safe (Green)\", \"Low-Risk (Yellow)\", \"Medium-Risk (Orange)\", \"High-Risk (Red)\"]\n",
    "    )\n",
    "\n",
    "    out_df = X_test_original.copy().reset_index(drop=True)\n",
    "    out_df[\"prob_leave\"] = probs\n",
    "    out_df[\"risk_zone\"] = zones \n",
    "\n",
    "    out_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Saved test set probabilities & zones to {output_csv}\")\n",
    "\n",
    "    # Print counts per risk zone\n",
    "    print(out_df[\"risk_zone\"].value_counts().reindex(\n",
    "        [\"Safe (Green)\", \"Low-Risk (Yellow)\", \"Medium-Risk (Orange)\", \"High-Risk (Red)\"]\n",
    "    ))\n",
    "\n",
    "    return out_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a36d8c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 8. Retention strategy suggestions (as function that returns actions) ----------\n",
    "def retention_strategies_for_zone(zone_label):\n",
    "    strategies = {\n",
    "        \"Safe (Green)\": [\n",
    "            \"Maintain engagement and recognition programs.\",\n",
    "            \"Monitor periodically; no immediate action required.\"\n",
    "        ],\n",
    "        \"Low-Risk (Yellow)\": [\n",
    "            \"Manager 1:1 check-ins to discuss satisfaction and workload.\",\n",
    "            \"Mentorship or small incentives; review career path opportunities.\"\n",
    "        ],\n",
    "        \"Medium-Risk (Orange)\": [\n",
    "            \"Proactive interventions: tailored development plan, compensation review.\",\n",
    "            \"Consider role re-assignment or flexible arrangements.\"\n",
    "        ],\n",
    "        \"High-Risk (Red)\": [\n",
    "            \"Immediate outreach: manager + HR retention interview.\",\n",
    "            \"Consider targeted counter-offers, rapid actions to resolve grievances, or job redesign.\"\n",
    "        ]\n",
    "    }\n",
    "    return strategies.get(zone_label, [\"No strategy found.\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41aadbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (14999, 10)\n",
      "\n",
      "--- Missing values ---\n",
      "satisfaction_level       0\n",
      "last_evaluation          0\n",
      "number_project           0\n",
      "average_montly_hours     0\n",
      "time_spend_company       0\n",
      "Work_accident            0\n",
      "left                     0\n",
      "promotion_last_5years    0\n",
      "sales                    0\n",
      "salary                   0\n",
      "dtype: int64\n",
      "\n",
      "--- Data types ---\n",
      "satisfaction_level       float64\n",
      "last_evaluation          float64\n",
      "number_project             int64\n",
      "average_montly_hours       int64\n",
      "time_spend_company         int64\n",
      "Work_accident              int64\n",
      "left                       int64\n",
      "promotion_last_5years      int64\n",
      "sales                     object\n",
      "salary                    object\n",
      "dtype: object\n",
      "\n",
      "--- Value counts for target 'left' ---\n",
      "left\n",
      "0    11428\n",
      "1     3571\n",
      "Name: count, dtype: int64\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\corr_matrix.png\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\hist_satisfaction_level.png\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\hist_last_evaluation.png\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\hist_average_montly_hours.png\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\proj_count_left_vs_stay.png\n",
      "Saved feature importances to D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\feature_importances.csv\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\feature_importances.png\n",
      "Saved logistic coefficients to D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\logistic_coefs.csv\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\kmeans_left_clusters.png\n",
      "Saved cluster centers to D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\kmeans_centers.csv\n",
      "\n",
      "--- CV (train, upsampled) for LogisticRegression ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8108    0.7700    0.7898      9142\n",
      "           1     0.7810    0.8203    0.8001      9142\n",
      "\n",
      "    accuracy                         0.7951     18284\n",
      "   macro avg     0.7959    0.7951    0.7950     18284\n",
      "weighted avg     0.7959    0.7951    0.7950     18284\n",
      "\n",
      "Test set: accuracy=0.7750 precision=0.5194 recall=0.7311 ROC_AUC=0.8244\n",
      "Confusion matrix (test):\n",
      " [[1803  483]\n",
      " [ 192  522]]\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\roc_LogisticRegression.png\n",
      "\n",
      "--- CV (train, upsampled) for RandomForest ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9786    0.9952    0.9868      9142\n",
      "           1     0.9951    0.9782    0.9866      9142\n",
      "\n",
      "    accuracy                         0.9867     18284\n",
      "   macro avg     0.9868    0.9867    0.9867     18284\n",
      "weighted avg     0.9868    0.9867    0.9867     18284\n",
      "\n",
      "Test set: accuracy=0.9900 precision=0.9900 recall=0.9678 ROC_AUC=0.9907\n",
      "Confusion matrix (test):\n",
      " [[2279    7]\n",
      " [  23  691]]\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\roc_RandomForest.png\n",
      "\n",
      "--- CV (train, upsampled) for GradientBoosting ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9576    0.9813    0.9693      9142\n",
      "           1     0.9808    0.9566    0.9685      9142\n",
      "\n",
      "    accuracy                         0.9689     18284\n",
      "   macro avg     0.9692    0.9689    0.9689     18284\n",
      "weighted avg     0.9692    0.9689    0.9689     18284\n",
      "\n",
      "Test set: accuracy=0.9667 precision=0.9229 recall=0.9384 ROC_AUC=0.9904\n",
      "Confusion matrix (test):\n",
      " [[2230   56]\n",
      " [  44  670]]\n",
      "Saved: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\roc_GradientBoosting.png\n",
      "\n",
      "Saved model summary to D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\model_summary.csv\n",
      "\n",
      "Best model chosen (recall-first): RandomForest\n",
      "test_precision    0.989971\n",
      "test_recall       0.967787\n",
      "test_accuracy         0.99\n",
      "test_roc_auc      0.990726\n",
      "Name: 1, dtype: object\n",
      "Saved test set probabilities & zones to D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\\hr_test_probs_with_zones.csv\n",
      "risk_zone\n",
      "Safe (Green)            2201\n",
      "Low-Risk (Yellow)        106\n",
      "Medium-Risk (Orange)      35\n",
      "High-Risk (Red)          658\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Retention strategy examples by zone:\n",
      "\n",
      " Safe (Green)\n",
      " - Maintain engagement and recognition programs.\n",
      " - Monitor periodically; no immediate action required.\n",
      "\n",
      " Low-Risk (Yellow)\n",
      " - Manager 1:1 check-ins to discuss satisfaction and workload.\n",
      " - Mentorship or small incentives; review career path opportunities.\n",
      "\n",
      " Medium-Risk (Orange)\n",
      " - Proactive interventions: tailored development plan, compensation review.\n",
      " - Consider role re-assignment or flexible arrangements.\n",
      "\n",
      " High-Risk (Red)\n",
      " - Immediate outreach: manager + HR retention interview.\n",
      " - Consider targeted counter-offers, rapid actions to resolve grievances, or job redesign.\n",
      "\n",
      "All outputs saved to: D:/Microsoft AI Engineer Program/Machine Learning using Python/Assessment/outputs\n",
      "Files: feature_importances.png, logistic_coefs.csv, model_summary.csv, hr_test_probs_with_zones.csv, kmeans_centers.csv, etc.\n"
     ]
    }
   ],
   "source": [
    "# ---------- Main pipeline ----------\n",
    "def main():\n",
    "    # 1. Load and QC\n",
    "    df = load_and_qc()\n",
    "\n",
    "    # 2. EDA plots\n",
    "    eda_plots(df)\n",
    "\n",
    "    # 3. Feature importance (returns data needed for modeling)\n",
    "    imp_df, coef_df, preprocess_info = feature_importance(df)\n",
    "    X_train_res_s, y_train_res, X_test_s, y_test, scaler, feature_names = preprocess_info\n",
    "\n",
    "    # 4. Clustering employees who left\n",
    "    cluster_left(df, n_clusters=3)\n",
    "\n",
    "    # 5. (SMOTE already applied above in feature_importance) If you want to run again:\n",
    "    # Example: X_res, y_res = apply_smote(X_train, y_train)\n",
    "\n",
    "    # 6. Train & evaluate models (CV + test)\n",
    "    summary, models = train_and_evaluate_models(X_train_res_s, y_train_res, X_test_s, y_test, feature_names)\n",
    "\n",
    "    # 7. Choose best model: prioritize recall on test set.\n",
    "    # summary is a list of dicts; pick model with highest test_recall. Tie-break on test_roc_auc.\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    best_idx = summary_df['test_recall'].idxmax()\n",
    "    # tie-breaker: if multiple same recall, pick highest ROC AUC\n",
    "    best_candidates = summary_df[summary_df['test_recall'] == summary_df.loc[best_idx,'test_recall']]\n",
    "    if len(best_candidates) > 1:\n",
    "        best_row = best_candidates.loc[best_candidates['test_roc_auc'].idxmax()]\n",
    "    else:\n",
    "        best_row = summary_df.loc[best_idx]\n",
    "    best_model_name = best_row['model']\n",
    "    best_model = models[best_model_name]\n",
    "    print(f\"\\nBest model chosen (recall-first): {best_model_name}\")\n",
    "    print(best_row[['test_precision','test_recall','test_accuracy','test_roc_auc']])\n",
    "\n",
    "    # 8. For saving risk zones we need the original X_test (unscaled, with same columns used earlier)\n",
    "    # Reconstruct dataset used earlier for 'feature_importance' step to obtain X_test_original:\n",
    "    df_enc = pd.get_dummies(df, columns=['sales','salary'], drop_first=True)\n",
    "    X_all = df_enc.drop('left', axis=1)\n",
    "    y_all = df_enc['left']\n",
    "    # Resplit to match previous train/test split (random_state = 42 was used earlier inside feature_importance split)\n",
    "    # Note: feature_importance used random_state=42 (here too). Use same random_state to align test indices.\n",
    "    X_train, X_test_original, y_train, y_test_original = train_test_split(X_all, y_all, test_size=0.2, stratify=y_all, random_state=42)\n",
    "    # Scale X_test_original using the scaler returned earlier\n",
    "    X_test_original_s = scaler.transform(X_test_original)\n",
    "\n",
    "    # Ensure best_model is fitted; if not, fit it on the resampled + scaled training set\n",
    "    if not hasattr(best_model, \"classes_\"):\n",
    "        best_model.fit(X_train_res_s, y_train_res)\n",
    "\n",
    "    # Save predictions & zones CSV\n",
    "    predict_and_save_risk_zones(best_model, scaler, X_test_original, X_test_original_s, output_csv=os.path.join(OUTDIR, \"hr_test_probs_with_zones.csv\"))\n",
    "\n",
    "    # 9. Print retention strategies sample\n",
    "    print(\"\\nRetention strategy examples by zone:\")\n",
    "    for z in [\"Safe (Green)\",\"Low-Risk (Yellow)\",\"Medium-Risk (Orange)\",\"High-Risk (Red)\"]:\n",
    "        print(\"\\n\", z)\n",
    "        for s in retention_strategies_for_zone(z):\n",
    "            print(\" -\", s)\n",
    "\n",
    "    print(\"\\nAll outputs saved to:\", OUTDIR)\n",
    "    print(\"Files: feature_importances.png, logistic_coefs.csv, model_summary.csv, hr_test_probs_with_zones.csv, kmeans_centers.csv, etc.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
